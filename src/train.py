import torch
import torch.nn
import torch.optim as optim
from tqdm import tqdm 
import os
from torchvision.utils import save_image

from generator import Generator
from discriminator import Discriminator
from dataset import MonetDataSet, MonetDataLoader
from torchvision import transforms


# ===========================================
# CONFIG
# ===========================================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 32
IMAGE_SIZE = 256
NOISE_DIM = 100
EPOCHS = 100
LEARNING_RATE = 2e-4
FEATURES_GEN = 64
FEATURES_DISC = 64
SAVE_DIR = "outputs/samples"

os.makedirs(SAVE_DIR, exist_ok=True)

# =========================================
# Transforms and Dataloader
# =========================================
transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), # ensure all images are of same size as model expects a fixed size input.
    transforms.ToTensor(), # converts from PIL.Image to torch.tensor
    transforms.Normalize([0.5], [0.5]) # normalize the images values to be between [-1.0, + 1.0]
])

dataLoader = MonetDataLoader(folder_path="data/gan-getting-started/monet_jpg/", transform=transform, batch_size=BATCH_SIZE).get_data_loader()

# ==========================================
# Models
# ==========================================
G = Generator(noise_dim=NOISE_DIM, feature_maps=FEATURES_GEN).to(DEVICE)
D = Discriminator(feature_maps=FEATURES_DISC).to(DEVICE)

# ==========================================
# Loss & Optimizers
# ==========================================

criterion = torch.nn.BCELoss() # Binary cross entropy loss
optimizer_G = optim.Adam(G.parameters(), lr = LEARNING_RATE, betas = (0.5, 0.999))
optimizer_D = optim.Adam(D.parameters(), lr = LEARNING_RATE, betas = (0.5, 0.999))

# Fixed noise for saving sample images
fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(DEVICE)

# ==========================================
# Training loop
# ==========================================

for epoch in range(EPOCHS):
    loop = tqdm(dataLoader, leave=True) # tqdm shows progress bar for loops. 
    for i, real in enumerate(loop): 
        real = real.to(DEVICE)
        batch_size = real.size(0) # get batch size
        noise = torch.randn(batch_size, NOISE_DIM, 1, 1).to(DEVICE) # generate noise randomly.

        # ================== Train Discriminator ==============
        fake = G(noise) # generate fake images by the generator. 
        D_real = D(real) # get predictions for real images
        D_fake = D(fake.detach()) # get predictions for fake images

        real_labels = torch.ones_like(D_real) # all real images true probability value is 1.0
        fake_labels = torch.zeros_like(D_fake) # all fake images true probability value is 0.0

        loss_D_real = criterion(D_real, real_labels) # compute loss for real images of discriminator
        loss_D_fake = criterion(D_fake, fake_labels) # compute loss for fake images of discriminator
        loss_D = loss_D_real + loss_D_fake # compute total loss - real loss + fake loss

        D.zero_grad() # clear all previous gradients
        loss_D.backward() # compute the gradients
        optimizer_D.step() # update the model weights using the Adam optimizer

        #================== Train Generator ==================
        output = D(fake) # generate output probabilities from the discriminator using the fake images generated by GAN. 
        loss_G = criterion(output, real_labels) # compute BCE loss between output and fake labelsl
        G.zero_grad() # clear all the past gradients of the generator
        loss_G.backward() # compute the gradients
        optimizer_G.step() # update the model weights using the Adam optimizer.

        #=======logging=========
        loop.set_description(f"Epoch [{epoch+1}/{EPOCHS}]")
        loop.set_postfix(D_loss=loss_D.item(), G_loss=loss_G.item())
    
    # save sample images at every epcoh
    with torch.no_grad():
        fake = G(fixed_noise) 
        fake = fake*0.5+ 0.5
        save_image(fake, os.path.join(SAVE_DIR, f"epoch_{epoch+1}.png"), nrow=8)


